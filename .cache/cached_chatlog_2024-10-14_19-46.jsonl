{"role": "user", "content": "### 3.1 Aggregate performance improves with model size but is worse than human performance\nThe performance of language models on the BIG-bench tasks improves with increased model size and the number of training examples (shots). Despite this improvement, even the best models score poorly compared to expert human raters, typically scoring under 20 on a normalized scale where 0 indicates poor performance and 100 indicates very good performance. The scoring system is based on a unique preferred metric for each task, accounting for high and low values set by task authors.\n\n### 3.2 Model predictions grow better calibrated with increased scale\nCalibration of model predictions, which refers to the accuracy of the model's confidence in its answers, tends to improve with the size of the model. However, all models assessed demonstrate poor calibration overall, as indicated by high Brier scores and Expected Calibration Error (ECE). This observation aligns with previous literature suggesting that larger models still struggle with reliable confidence estimates, although calibration does improve with model size.\n\n### 3.3 Model classes behave similarly, with benefits from sparsity\nDifferent model classes (dense and sparse models) exhibit similar cross-entropy measures, indicating comparable performance. Sparse BIG-G models show about double the inference efficiency compared to dense models while achieving equivalent performance. Notably, sparse models significantly enhance calibration compared to dense models, demonstrating a tenfold improvement in calibration per FLOP-matched parameter count.\n\n### 3.4 Linearity and breakthroughness: categorizing scaling behaviors\nTasks exhibit varying scaling behaviors categorized into two metrics: linearity (consistent performance improvement with scale) and breakthroughness (sudden performance gains at specific scales). Tasks with high linearity often involve simple factual knowledge and text manipulation, while those requiring sequential reasoning or composite skills tend to exhibit breakthrough behavior. A minority of tasks demonstrate model performance degradation with scale.\n\n### 3.4.1 Properties of tasks with high linearity or breakthroughness\nHigh linearity tasks primarily involve memorization and straightforward reasoning, while breakthrough tasks necessitate applying multiple reasoning steps. Although examples of this behavior are noted, these findings warrant further exploration beyond the current analysis.\n\n### 3.4.2 Breakthrough behavior is sensitive to details of task specification\nThe perception of sudden skill acquisition may mask underlying smooth improvements in model capability. Metrics like exact string match can create a misleading perception of abrupt breakthroughs, while alternative metrics may reveal more gradual enhancements. Decomposing tasks into subtasks helps track progress and observe smoother performance gains.\n\n### 3.4.3 Even programmatic measures of model capability can be highly subjective\nThe evaluation metrics and task designs significantly affect how model capabilities are perceived. Different formulations of the same task can yield varying results, underscoring the need for careful examination of outputs to ensure that they align with intended task measurements, especially in few-shot settings.\n\n### 3.5 Even large language models are brittle\nLarge language models show sensitivity to the phrasing of questions, impacting their performance across similar tasks. For example, models perform better on multiple-choice questions without presenting answer choices, and their performance varies significantly based on how causal relationships are framed. This brittleness remains an area of exploration, though larger models may exhibit improved robustness to phrasing changes.\n\n### 3.6 Social bias in large language models\nThe examination of social bias in language models shows that bias often increases with model scale in ambiguous contexts, but can decrease in unambiguous settings. Properly designed prompts can also steer model outputs and mitigate bias. Findings from various tasks indicate that bias counteraction is possible through careful prompting, particularly in challenging contexts.\n\n### 3.7 Performance on non-English languages\nLanguage models generally perform better in English than in non-English languages, notably struggling with tasks in low-resource languages or languages with non-Latin scripts. While some performance gains are observed with increasing scale in specific non-English tasks, on the whole, considerable gaps remain, suggesting that improvements require deliberate data gathering and model design considerations, independent of scale. For low-resource languages, performance tends to remain close to chance, indicating significant challenges in those areas.\n\nTranslate given text as Korean"}
{"role": "assistant", "content": "### 3.1 \ubaa8\ub378 \ud06c\uae30\uac00 \ucee4\uc9c8\uc218\ub85d \uc9d1\ud569 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\uc9c0\ub9cc \uc778\uac04 \uc131\ub2a5\ubcf4\ub2e4 \ub0ae\uc74c\n\uc5b8\uc5b4 \ubaa8\ub378\uc758 BIG-bench \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5\uc740 \ubaa8\ub378 \ud06c\uae30\uc640 \ud6c8\ub828 \uc608\uc81c(\uc0f7)\uc758 \uc218\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ud5a5\uc0c1\ub429\ub2c8\ub2e4. \uadf8\ub7fc\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0 \uac00\uc7a5 \uc88b\uc740 \ubaa8\ub378\uc870\ucc28 \uc804\ubb38\uac00 \uc778\uac04 \ud3c9\uac00\uc790\uc5d0 \ube44\ud574 \uc131\uc801\uc774 \ub0ae\uc73c\uba70, \uc77c\ubc18\uc801\uc73c\ub85c 0\uc774 \ub0ae\uc740 \uc131\ub2a5\uc744 \uc758\ubbf8\ud558\uace0 100\uc774 \ub9e4\uc6b0 \uc88b\uc740 \uc131\ub2a5\uc744 \uc758\ubbf8\ud558\ub294 \uc815\uaddc\ud654\ub41c \ucc99\ub3c4\uc5d0\uc11c 20\uc810 \uc774\ud558\uc5d0 \uadf8\uce69\ub2c8\ub2e4. \uc774 \uc810\uc218 \uc2dc\uc2a4\ud15c\uc740 \uac01 \uc791\uc5c5\uc5d0 \ub300\ud574 \uace0\uc720\ud55c \uc120\ud638 \uc9c0\ud45c\ub97c \uae30\ubc18\uc73c\ub85c \ud558\uba70, \uc791\uc5c5 \uc800\uc790\uac00 \uc124\uc815\ud55c \ub192\uc740 \uac12\uacfc \ub0ae\uc740 \uac12\uc744 \uace0\ub824\ud569\ub2c8\ub2e4.\n\n### 3.2 \ubaa8\ub378 \uc608\uce21\uc740 \uaddc\ubaa8\uac00 \ucee4\uc9c8\uc218\ub85d \ub354 \uc798 \ubcf4\uc815\ub428\n\ubaa8\ub378 \uc608\uce21\uc758 \ubcf4\uc815(calibration)\uc740 \ubaa8\ub378\uc758 \ub2f5\ubcc0\uc5d0 \ub300\ud55c \uc2e0\ub8b0\ub3c4\uc758 \uc815\ud655\uc131\uc744 \uc758\ubbf8\ud558\uba70, \ubaa8\ub378 \uaddc\ubaa8\uac00 \ucee4\uc9c8\uc218\ub85d \ubcf4\uc815\uc774 \ud5a5\uc0c1\ub418\ub294 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \ud3c9\uac00\ub41c \ubaa8\ub4e0 \ubaa8\ub378\uc740 \ub192\uc740 Brier \uc810\uc218\uc640 \uae30\ub300 \ubcf4\uc815 \uc624\ucc28(ECE)\ub85c \ub098\ud0c0\ub09c \ubc14\uc640 \uac19\uc774 \uc804\ubc18\uc801\uc73c\ub85c \ub0ae\uc740 \ubcf4\uc815\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uad00\ucc30\uc740 \uc774\uc804 \ubb38\ud5cc\uacfc \uc77c\uce58\ud558\uba70, \ub354 \ud070 \ubaa8\ub378\uc774 \uc5ec\uc804\ud788 \uc2e0\ub8b0\ud560 \uc218 \uc788\ub294 \uc2e0\ub8b0\ub3c4 \ucd94\uc815\uc5d0 \uc5b4\ub824\uc6c0\uc744 \uacaa\uace0 \uc788\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub2e4\ub9cc \ubcf4\uc815\uc740 \ubaa8\ub378 \ud06c\uae30\uc5d0 \ub530\ub77c \uac1c\uc120\ub429\ub2c8\ub2e4.\n\n### 3.3 \ubaa8\ub378 \ud074\ub798\uc2a4\ub294 \uc720\uc0ac\ud558\uac8c \ud589\ub3d9\ud558\uba70 \ud76c\uc18c\uc131\uc758 \uc774\uc810\uc774 \uc788\uc74c\n\ub2e4\uc591\ud55c \ubaa8\ub378 \ud074\ub798\uc2a4(\ubc00\uc9d1 \ubaa8\ub378 \ubc0f \ud76c\uc18c \ubaa8\ub378)\ub294 \uad50\ucc28 \uc5d4\ud2b8\ub85c\ud53c \uce21\uc815\uac12\uc774 \uc720\uc0ac\ud558\uc5ec \ube44\uc2b7\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \ud76c\uc18c BIG-G \ubaa8\ub378\uc740 \ubc00\uc9d1 \ubaa8\ub378\uc5d0 \ube44\ud574 \uc57d \ub450 \ubc30\uc758 \ucd94\ub860 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc8fc\uba70 \ub3d9\ub4f1\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4. \ud2b9\ud788, \ud76c\uc18c \ubaa8\ub378\uc740 \ubc00\uc9d1 \ubaa8\ub378\ubcf4\ub2e4 \ubcf4\uc815\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ucf1c, \ub9e4 FLOP-\uc77c\uce58 \ub9e4\uac1c\ubcc0\uc218 \uc218\uc5d0\uc11c \ubcf4\uc815\uc774 10\ubc30 \uac1c\uc120\ub429\ub2c8\ub2e4.\n\n### 3.4 \uc120\ud615\uc131 \ubc0f \ub3cc\ud30c\ub825: \ud06c\uae30 \ubcc0\ud654 \ud589\ub3d9 \ubc94\uc8fc\ud654\n\uc791\uc5c5\uc740 \uc120\ud615\uc131(\uaddc\ubaa8\uc5d0 \ub530\ub978 \uc77c\uad00\ub41c \uc131\ub2a5 \ud5a5\uc0c1)\uacfc \ub3cc\ud30c\ub825(\ud2b9\uc815 \uaddc\ubaa8\uc5d0\uc11c\uc758 \uac11\uc791\uc2a4\ub7ec\uc6b4 \uc131\ub2a5 \ud5a5\uc0c1)\uc758 \ub450 \uac00\uc9c0 \uc9c0\ud45c\ub85c \ubd84\ub958\ub41c \ub2e4\uc591\ud55c \ud06c\uae30 \ubcc0\ud654 \ud589\ub3d9\uc744 \ubcf4\uc785\ub2c8\ub2e4. \ub192\uc740 \uc120\ud615\uc131\uc758 \uc791\uc5c5\uc740 \uc885\uc885 \uac04\ub2e8\ud55c \uc0ac\uc2e4 \uc9c0\uc2dd\uacfc \ud14d\uc2a4\ud2b8 \uc870\uc791\uc744 \ud3ec\ud568\ud558\uba70, \uc21c\ucc28\uc801 \ucd94\ub860\uc774\ub098 \ubcf5\ud569 \uae30\uc220\uc774 \ud544\uc694\ud55c \uc791\uc5c5\uc740 \ub3cc\ud30c\ub825 \ud589\ub3d9\uc744 \ubcf4\uc774\ub294 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc18c\uc218\uc758 \uc791\uc5c5\uc740 \uaddc\ubaa8\uac00 \ucee4\uc9c8\uc218\ub85d \ubaa8\ub378 \uc131\ub2a5\uc774 \uc800\ud558\ub418\ub294 \uacbd\ud5a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.\n\n### 3.4.1 \ub192\uc740 \uc120\ud615\uc131 \ub610\ub294 \ub3cc\ud30c\ub825\uc758 \uc791\uc5c5 \uc18d\uc131\n\ub192\uc740 \uc120\ud615\uc131 \uc791\uc5c5\uc740 \uc8fc\ub85c \uc554\uae30\uc640 \uac04\ub2e8\ud55c \ucd94\ub860\uc744 \ud3ec\ud568\ud558\uba70, \ub3cc\ud30c\ub825 \uc791\uc5c5\uc740 \uc5ec\ub7ec \ub2e8\uacc4\uc758 \ucd94\ub860\uc744 \uc801\uc6a9\ud574\uc57c \ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ud589\ub3d9\uc758 \uc0ac\ub840\uac00 \uc788\uc9c0\ub9cc, \uc774\ub7ec\ud55c \ubc1c\uacac\uc740 \ud604\uc7ac \ubd84\uc11d\uc744 \ub118\uc5b4\uc11c \ucd94\uac00 \ud0d0\uad6c\uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\n\n### 3.4.2 \ub3cc\ud30c\ub825 \ud589\ub3d9\uc740 \uc791\uc5c5 \uba85\uc138\uc758 \uc138\ubd80 \uc0ac\ud56d\uc5d0 \ubbfc\uac10\ud568\n\uac11\uc791\uc2a4\ub7ec\uc6b4 \uae30\uc220 \uc2b5\ub4dd\uc758 \uc778\uc2dd\uc740 \ubaa8\ub378 \ub2a5\ub825\uc758 \uadfc\ubcf8\uc801\uc778 \ubd80\ub4dc\ub7ec\uc6b4 \uac1c\uc120\uc744 \uac00\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc815\ud655\ud55c \ubb38\uc790\uc5f4 \uc77c\uce58\uc640 \uac19\uc740 \uba54\ud2b8\ub9ad\uc740 \uac11\uc791\uc2a4\ub7ec\uc6b4 \ub3cc\ud30c\ub825\uc758 \uc798\ubabb\ub41c \uc778\uc2dd\uc744 \ucd08\ub798\ud560 \uc218 \uc788\uc73c\uba70, \ub300\uc548 \uba54\ud2b8\ub9ad\uc774 \ubcf4\ub2e4 \uc810\uc9c4\uc801\uc778 \ud5a5\uc0c1\uc744 \ub4dc\ub7ec\ub0bc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc791\uc5c5\uc744 \ud558\uc704 \uc791\uc5c5\uc73c\ub85c \ubd84\ud574\ud558\uba74 \uc9c4\ud589 \uc0c1\ud669\uc744 \ucd94\uc801\ud558\uace0 \ubcf4\ub2e4 \ub9e4\ub044\ub7ec\uc6b4 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uad00\ucc30\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n### 3.4.3 \ud504\ub85c\uadf8\ub7a8\uc801 \ubaa8\ub378 \ub2a5\ub825 \uce21\uc815\ub3c4 \ub9e4\uc6b0 \uc8fc\uad00\uc801\uc77c \uc218 \uc788\uc74c\n\ubaa8\ub378 \ub2a5\ub825\uc758 \ud3c9\uac00 \uba54\ud2b8\ub9ad\uacfc \uc791\uc5c5 \uc124\uacc4\ub294 \ubaa8\ub378 \ub2a5\ub825\uc744 \uc778\uc2dd\ud558\ub294 \ub370 \uc0c1\ub2f9\ud55c \uc601\ud5a5\uc744 \ubbf8\uce69\ub2c8\ub2e4. \ub3d9\uc77c\ud55c \uc791\uc5c5\uc758 \ub2e4\uc591\ud55c \ud615\uc2dd\uc774 \uc0c1\uc774\ud55c \uacb0\uacfc\ub97c \uac00\uc838\uc62c \uc218 \uc788\uc73c\ubbc0\ub85c, \ud2b9\ud788 \uba87 \uc0f7 \uc124\uc815\uc5d0\uc11c \uc758\ub3c4\ud55c \uc791\uc5c5 \uce21\uc815\uacfc \uc77c\uce58\ud558\ub3c4\ub85d \ucd9c\ub825\uc758 \uba74\ubc00\ud55c \uac80\ud1a0\uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\n\n### 3.5 \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc190\uc0c1\uc131\n\ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378\uc740 \uc9c8\ubb38\uc758 phrasing\uc5d0 \ub300\ud574 \ubbfc\uac10\ud558\uac8c \ubc18\uc751\ud558\uc5ec \uc720\uc0ac\ud55c \uc791\uc5c5\uc5d0\uc11c \uc131\ub2a5\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce69\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \ubaa8\ub378\uc740 \uc120\ud0dd\uc9c0\ub97c \uc81c\uc2dc\ud558\uc9c0 \uc54a\uc740 \uac1d\uad00\uc2dd \uc9c8\ubb38\uc5d0\uc11c \ub354 \uc798 \uc218\ud589\ud558\uba70, \uc778\uacfc \uad00\uacc4\uc758 \ud615\uc2dd\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \ud06c\uac8c \ub2ec\ub77c\uc9d1\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc190\uc0c1\uc131\uc740 \uc5ec\uc804\ud788 \ud0d0\uad6c \ub300\uc0c1\uc774\uba70, \ub354 \ud070 \ubaa8\ub378\uc740 phrasing \ubcc0\ud654\uc5d0 \ub300\ud574 \ub354 \ud5a5\uc0c1\ub41c \uac15\uac74\ud568\uc744 \ubcf4\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n### 3.6 \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc0ac\ud68c\uc801 \ud3b8\ud5a5\n\uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc0ac\ud68c\uc801 \ud3b8\ud5a5 \uc870\uc0ac\ub294 \ubd88\ubd84\uba85\ud55c \uc0c1\ud669\uc5d0\uc11c \ud3b8\ud5a5\uc774 \ubaa8\ub378 \uaddc\ubaa8\uc640 \ud568\uaed8 \uc99d\uac00\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc9c0\ub9cc, \uba85\ud655\ud55c \uc0c1\ud669\uc5d0\uc11c\ub294 \uac10\uc18c\ud560 \uc218\ub3c4 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc801\uc808\ud558\uac8c \uc124\uacc4\ub41c \ud504\ub86c\ud504\ud2b8\ub294 \ubaa8\ub378 \ucd9c\ub825\uc744 \uc720\ub3c4\ud558\uace0 \ud3b8\ud5a5\uc744 \uc644\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub2e4\uc591\ud55c \uc791\uc5c5\uc758 \uacb0\uacfc\ub294 \ud2b9\ubcc4\ud788 \ub3c4\uc804\uc801\uc778 \ubb38\ub9e5\uc5d0\uc11c \uc2e0\uc911\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \ud1b5\ud574 \ud3b8\ud5a5 \uc800\ud56d\uc774 \uac00\ub2a5\ud568\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.\n\n### 3.7 \ube44\uc601\uc5b4 \uc5b8\uc5b4\uc5d0\uc11c\uc758 \uc131\ub2a5\n\uc5b8\uc5b4 \ubaa8\ub378\uc740 \uc77c\ubc18\uc801\uc73c\ub85c \ube44\uc601\uc5b4 \uc5b8\uc5b4\ubcf4\ub2e4 \uc601\uc5b4\uc5d0\uc11c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\uba70, \ud2b9\ud788 \uc800\uc790\uc6d0 \uc5b8\uc5b4 \ub610\ub294 \ube44\ub77c\ud2f4 \uc2a4\ud06c\ub9bd\ud2b8\ub97c \uc0ac\uc6a9\ud558\ub294 \uc5b8\uc5b4\uc5d0\uc11c \uc5b4\ub824\uc6c0\uc744 \uacaa\uc2b5\ub2c8\ub2e4. \ud2b9\uc815 \ube44\uc601\uc5b4 \uc791\uc5c5\uc5d0\uc11c \uaddc\ubaa8\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc131\ub2a5 \ud5a5\uc0c1\uc774 \uad00\ucc30\ub418\uc9c0\ub9cc, \uc804\uccb4\uc801\uc73c\ub85c \uc0c1\ub2f9\ud55c \uaca9\ucc28\uac00 \ub0a8\uc544 \uc788\uc5b4 \uac1c\uc120\uc744 \uc704\ud574\uc11c\ub294 \uc758\ub3c4\uc801\uc778 \ub370\uc774\ud130 \uc218\uc9d1 \ubc0f \ubaa8\ub378 \uc124\uacc4 \uace0\ub824\uac00 \ud544\uc694\ud569\ub2c8\ub2e4. \uc800\uc790\uc6d0 \uc5b8\uc5b4\uc758 \uacbd\uc6b0 \uc131\ub2a5\uc774 \uc6b0\uc5f0\uc5d0 \uac00\uae4c\uc6b4 \uc218\uc900\uc5d0 \uba38\ubb3c\ub7ec \uc788\uc5b4 \uc774\ub7ec\ud55c \uc601\uc5ed\uc5d0\uc11c \uc0c1\ub2f9\ud55c \ub3c4\uc804\uc774 \ud544\uc694\ud568\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4."}
